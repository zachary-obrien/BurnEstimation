{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EENG 5300 Kaggle Competition - CNN",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9crpKwFFGjl",
        "outputId": "a2d32970-66d8-4a42-965a-33109816e4af"
      },
      "source": [
        "!curl -L \"https://docs.google.com/uc?export=download&id=1CgR9w26BU4nli_ecg-3Ukgc06NNOD3BD\" > csce5300-prediction-competition.zip\n",
        "!unzip csce5300-prediction-competition.zip -d ./"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   388    0   388    0     0    889      0 --:--:-- --:--:-- --:--:--   889\n",
            "100  129k  100  129k    0     0   180k      0 --:--:-- --:--:-- --:--:--  180k\n",
            "Archive:  csce5300-prediction-competition.zip\n",
            "replace ./sample_prediction.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: ./sample_prediction.csv  \n",
            "  inflating: ./test_luc.csv          \n",
            "  inflating: ./train_luc.csv         \n",
            "  inflating: ./tutorial_code.ipynb   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvHvW1IVCg8z"
      },
      "source": [
        "#%%\n",
        "\n",
        "# This is a tutorial to create a simple prediction model to perform the following\n",
        "# 1. Read in and show basic information about the training data\n",
        "# 2. Create a simple prediction model on a portion of the training data\n",
        "# 3. Test the quality of the model on a later portion of the data\n",
        "# 4. Create a final model using all the training data based on the best choices above\n",
        "# 5. Apply that model to the test data, to be scored on the kaggle.com site\n",
        "\n",
        "# FILES NEEDED: for this code to work, you will need train_luc.csv and test_luc.csv\n",
        "# in the same folder as this notebook"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-Bbcy9HCUVb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv as csv\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "boR3MUtfCV4y",
        "outputId": "d5f8c41e-1252-43ac-f3b5-5870d0ee4b8f"
      },
      "source": [
        "# read the data and display the first 5 rows\n",
        "train_df = pd.read_csv('train_luc.csv', header=0)\n",
        "\n",
        "print(\"\\nNumber of samples:\",train_df.shape[0],\"and number of features:\",train_df.shape[1],\"\\n\")\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Number of samples: 9174 and number of features: 12 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              datetime  season  holiday  ...  casual  registered  count\n",
              "0  2011-01-01 00:00:00       1        0  ...       3          13     16\n",
              "1  2011-01-01 01:00:00       1        0  ...       8          32     40\n",
              "2  2011-01-01 02:00:00       1        0  ...       5          27     32\n",
              "3  2011-01-01 03:00:00       1        0  ...       3          10     13\n",
              "4  2011-01-01 04:00:00       1        0  ...       0           1      1\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1m7Zg97CbEV"
      },
      "source": [
        "# Understanding basic stats of the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "gc0DKfRMCZho",
        "outputId": "2a2699ed-f6f0-4e17-dd54-8268f00c5632"
      },
      "source": [
        "# read about the data elsewhere, however, it is critical to observe the data to make sure\n",
        "# everything is read in correctly and matches the description\n",
        "\n",
        "train_df.describe()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>9174.000000</td>\n",
              "      <td>9174.000000</td>\n",
              "      <td>9174.000000</td>\n",
              "      <td>9174.000000</td>\n",
              "      <td>9174.000000</td>\n",
              "      <td>9174.000000</td>\n",
              "      <td>9174.000000</td>\n",
              "      <td>9174.000000</td>\n",
              "      <td>9174.000000</td>\n",
              "      <td>9174.000000</td>\n",
              "      <td>9174.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.505559</td>\n",
              "      <td>0.031284</td>\n",
              "      <td>0.678875</td>\n",
              "      <td>1.414868</td>\n",
              "      <td>20.130401</td>\n",
              "      <td>23.578433</td>\n",
              "      <td>61.715064</td>\n",
              "      <td>12.737931</td>\n",
              "      <td>35.713647</td>\n",
              "      <td>154.868106</td>\n",
              "      <td>190.581753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.116618</td>\n",
              "      <td>0.174094</td>\n",
              "      <td>0.466934</td>\n",
              "      <td>0.635363</td>\n",
              "      <td>7.940504</td>\n",
              "      <td>8.617957</td>\n",
              "      <td>19.401829</td>\n",
              "      <td>8.199027</td>\n",
              "      <td>49.667738</td>\n",
              "      <td>150.981155</td>\n",
              "      <td>181.011530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.940000</td>\n",
              "      <td>16.665000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>7.001500</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>41.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>24.240000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>11.001400</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>144.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>27.060000</td>\n",
              "      <td>31.060000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>16.997900</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>222.000000</td>\n",
              "      <td>282.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>45.455000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>56.996900</td>\n",
              "      <td>362.000000</td>\n",
              "      <td>886.000000</td>\n",
              "      <td>977.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            season      holiday  ...   registered        count\n",
              "count  9174.000000  9174.000000  ...  9174.000000  9174.000000\n",
              "mean      2.505559     0.031284  ...   154.868106   190.581753\n",
              "std       1.116618     0.174094  ...   150.981155   181.011530\n",
              "min       1.000000     0.000000  ...     0.000000     1.000000\n",
              "25%       2.000000     0.000000  ...    35.000000    41.000000\n",
              "50%       3.000000     0.000000  ...   117.000000   144.000000\n",
              "75%       4.000000     0.000000  ...   222.000000   282.000000\n",
              "max       4.000000     1.000000  ...   886.000000   977.000000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MloNZE7nCkx3"
      },
      "source": [
        "# Create a new feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "j1H7125gCnt7",
        "outputId": "87ef5d78-93d5-426a-c5df-3773884580ec"
      },
      "source": [
        "# let's take datetime (which isn't very useful to algorithms) and turn it into something useful.\n",
        "# e.g. this will create a new column for the hour\n",
        "def hour_of_day(dt):\n",
        "    return datetime.strptime(dt, \"%Y-%m-%d %H:%M:%S\").time().hour\n",
        "train_df['hour'] = train_df['datetime'].map(hour_of_day)\n",
        "train_df.head()\n",
        "# note the new column on the right labelled \"hour\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "      <th>hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              datetime  season  holiday  ...  registered  count  hour\n",
              "0  2011-01-01 00:00:00       1        0  ...          13     16     0\n",
              "1  2011-01-01 01:00:00       1        0  ...          32     40     1\n",
              "2  2011-01-01 02:00:00       1        0  ...          27     32     2\n",
              "3  2011-01-01 03:00:00       1        0  ...          10     13     3\n",
              "4  2011-01-01 04:00:00       1        0  ...           1      1     4\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP_wbQlzCpCR"
      },
      "source": [
        "# Make visualizations to better understand your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "ey4v3Kd0CrFc",
        "outputId": "cad355a3-f89e-4306-89be-fe0964c9cfbe"
      },
      "source": [
        "# now let's take a look at the amerage amount of bike use for each hour of the day\n",
        "# as a \"sanity check\" to make sure the data makes sense before going further\n",
        "hours = np.unique(train_df['hour'])\n",
        "print(\"hours:\",hours)\n",
        "\n",
        "hours_mean = {}\n",
        "for h in hours:\n",
        "    temp_df = train_df.loc[train_df['hour'] == h]\n",
        "    hours_mean[h] = temp_df['count'].mean()\n",
        "\n",
        "# plot the results. Maybe should see peaks from bike commuting or evening use\n",
        "plt.bar(hours,[hours_mean[h] for h in hours])\n",
        "plt.xlabel(\"hour\")\n",
        "plt.ylabel(\"average number of bikes used\")\n",
        "plt.title(\"Measured bike use over 2 years\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hours: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Measured bike use over 2 years')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT8dwEdrCsZm"
      },
      "source": [
        "# Pick the features and the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeuvoQfUCtLf",
        "outputId": "43ca5ec4-45ee-4c82-bb01-0c73a0cdae32"
      },
      "source": [
        "# pick your features\n",
        "# cols = ['hour'] # clearly a simple model\n",
        "# try more features later, like...\n",
        "# cols = ['hour','season']\n",
        "required_cols = [\"hour\"]\n",
        "cols = ['season', \"holiday\", \"workingday\", \"weather\", \"atemp\", \"temp\", \"humidity\", \"windspeed\"]\n",
        "#cols = ['hour', 'season', 'workingday', 'weather', 'atemp']\n",
        "\n",
        "# pick your model (you should consider adjusting optional parameters too)\n",
        "# reading in a few models we can pick from (there are many others)\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# pick one by commenting/uncommenting\n",
        "model1 = DecisionTreeRegressor()\n",
        "model2 = LinearRegression()\n",
        "model3 = KNeighborsRegressor(n_neighbors = 5)\n",
        "model4 = LinearSVR(max_iter=10000)\n",
        "model5 = RandomForestRegressor(n_estimators = 1)\n",
        "\n",
        "model_list = [model1, model2, model3, model4, model5]\n",
        "\n",
        "print(\"columns selected for later:\",cols)\n",
        "print(model4) # to get an idea of parameters and confirm model chosen"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "columns selected for later: ['season', 'holiday', 'workingday', 'weather', 'atemp', 'temp', 'humidity', 'windspeed']\n",
            "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
            "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=10000,\n",
            "          random_state=None, tol=0.0001, verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQczluI-2qQM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "random_forest_cols = ['hour', 'season', 'holiday', 'workingday', 'weather', 'temp', 'humidity']\n",
        "\n",
        "train_vals = train_df[random_forest_cols]\n",
        "train_results = train_df['count']\n",
        "\n",
        "train_vals_cnn = train_vals.to_numpy()\n",
        "train_results_cnn = train_results.to_numpy()\n",
        "\n",
        "#train_vals_cnn = train_vals_cnn.reshape(train_vals_cnn.shape[0], \n",
        "#                                        train_vals_cnn.shape[1], 1)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(train_vals_cnn, train_results_cnn, \n",
        "                                                test_size=.3, random_state=42)\n",
        "\n",
        "for n in range(1, 1):\n",
        "    rf_model = RandomForestRegressor(n_estimators = n)\n",
        "\n",
        "    rf_model.fit(xtrain, ytrain)\n",
        "\n",
        "    ypred = rf_model.predict(xtest)\n",
        "\n",
        "    # score the model on the new test set\n",
        "    rms = np.sqrt(mean_squared_error(ytest, ypred))\n",
        "\n",
        "    print(n, \":\",rms)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yXxjJQjwLse"
      },
      "source": [
        "import itertools\n",
        "\n",
        "all_combinations = []\n",
        "for r in range(len(cols) + 1):\n",
        "    combinations_object = itertools.combinations(cols, r)\n",
        "    combinations_list = list(combinations_object)\n",
        "    all_combinations += combinations_list\n",
        "\n",
        "# for combo in all_combinations:\n",
        "#     print(list(combo))\n",
        "\n",
        "#Test 1\n",
        "#all_combinations = [cols]\n",
        "# all_combinations = [['season', 'holiday', 'workingday', 'weather', 'temp', 'humidity'],\n",
        "#                     ['season', 'holiday', 'workingday', 'weather', 'temp', 'humidity', 'windspeed']\n",
        "#                     ]\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhtjGUBf4qvi",
        "outputId": "8ad83cf8-35d5-44f6-f068-8abc2870b185"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "for combo in all_combinations:\n",
        "    combo = list(combo)\n",
        "    if len(combo) >= 2: \n",
        "        random_forest_cols = required_cols + combo\n",
        "        print(\"Starting with columns:\", random_forest_cols)\n",
        "        train_vals = train_df[random_forest_cols]\n",
        "        train_results = train_df['count']\n",
        "\n",
        "        train_vals_rf = train_vals.to_numpy()\n",
        "        train_results_rf = train_results.to_numpy()\n",
        "\n",
        "\n",
        "        xtrain, xtest, ytrain, ytest=train_test_split(train_vals_cnn, train_results_cnn, \n",
        "                                                test_size=.1, random_state=42)\n",
        "        # Number of trees in random forest\n",
        "        n_estimators = [int(x) for x in np.linspace(start = 1, stop = 1000, num = 10)]\n",
        "        # Number of features to consider at every split\n",
        "        max_features = ['auto', 'sqrt']\n",
        "        # Maximum number of levels in tree\n",
        "        max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "        max_depth.append(None)\n",
        "        # Minimum number of samples required to split a node\n",
        "        min_samples_split = [2, 5, 10]\n",
        "        # Minimum number of samples required at each leaf node\n",
        "        min_samples_leaf = [1, 2, 4]\n",
        "        # Method of selecting samples for training each tree\n",
        "        bootstrap = [True, False]\n",
        "\n",
        "        # Create the random grid\n",
        "        random_grid = {'n_estimators': n_estimators,\n",
        "                    'max_features': max_features,\n",
        "                    'max_depth': max_depth,\n",
        "                    'min_samples_split': min_samples_split,\n",
        "                    'min_samples_leaf': min_samples_leaf,\n",
        "                    'bootstrap': bootstrap}\n",
        "\n",
        "        # Use the random grid to search for best hyperparameters\n",
        "        # First create the base model to tune\n",
        "        rf = RandomForestRegressor(random_state = 42)\n",
        "        # Random search of parameters, using 3 fold cross validation, \n",
        "        # search across 100 different combinations, and use all available cores\n",
        "        rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
        "                                    n_iter = 100, scoring='neg_root_mean_squared_error', \n",
        "                                    cv = 10, verbose=0, random_state=42, n_jobs=3,\n",
        "                                    return_train_score=True)\n",
        "\n",
        "        # Fit the random search model\n",
        "        rf_random.fit(xtrain, ytrain)\n",
        "        # rf_model = RandomForestRegressor(n_estimators = 10)\n",
        "        #   predict on the testing subset of the original training data\n",
        "        ypred = rf_random.predict(xtest)\n",
        "\n",
        "        # score the model on the new test set\n",
        "        rms = np.sqrt(mean_squared_error(ytest, ypred))\n",
        "        # rf_model.fit(train_vals_cnn, train_results_cnn)\n",
        "        print(rms, \"For params:\", rf_random.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting with columns: ['hour', 'season', 'holiday']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyDr_meO_hUx",
        "outputId": "a3ec19e0-7752-4fb7-9a94-1c1d582e3e00"
      },
      "source": [
        "import sklearn \n",
        "print(sorted(sklearn.metrics.SCORERS.keys()))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'balanced_accuracy', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted', 'max_error', 'mutual_info_score', 'neg_brier_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_gamma_deviance', 'neg_mean_poisson_deviance', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'neg_root_mean_squared_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'roc_auc_ovo', 'roc_auc_ovo_weighted', 'roc_auc_ovr', 'roc_auc_ovr_weighted', 'v_measure_score']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX78ODSfCvoF"
      },
      "source": [
        "# Separate your training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCsX1809CwjR",
        "outputId": "bb1c1e21-2e5e-4876-8b5f-c6fc21db9a48"
      },
      "source": [
        "# this is a way of splitting training and testing by hand\n",
        "# however, there are tools to do this automatically\n",
        "# google \"cross validation\" for a better/more advanced strategy\n",
        "#--------------------\n",
        "\n",
        "n = len(train_df) # get number of rows in the training set\n",
        "training_size = 0.75 # fraction of training data to split off for internal testing\n",
        "\n",
        "# set up separate training and testing sets\n",
        "# in this case using shuffled array indices\n",
        "# there are many more ways to do this too\n",
        "indices = np.array(range(n)) # makes an array of row indices in order\n",
        "from numpy.random import shuffle\n",
        "shuffle(indices)\n",
        "split_point = int(n*training_size)\n",
        "mytrain_i = indices[0:split_point]\n",
        "mytest_i = indices[split_point:]\n",
        "\n",
        "# now use those shuffled indices to separating training from test dataframes\n",
        "new_train_df = train_df.iloc[mytrain_i]\n",
        "new_test_df = train_df.iloc[mytest_i]\n",
        "\n",
        "print(\"samples in the new training subset:\",len(new_train_df))\n",
        "print(\"samples in the new test subset:\",len(new_test_df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "samples in the new training subset: 6880\n",
            "samples in the new test subset: 2294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_38KW7nCyn3"
      },
      "source": [
        "# Fit the model to a portion of the training set, test on the rest and evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz3V8VTaMwL4",
        "outputId": "93618db5-ba5e-4aa8-f688-5b924edd2776"
      },
      "source": [
        "print(cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['season', 'holiday', 'workingday', 'weather', 'atemp', 'temp', 'humidity', 'windspeed']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JWDku3hrqYM"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten, Dropout, MaxPool1D, BatchNormalization, LeakyReLU,  ReLU\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras import losses, regularizers\n",
        "\n",
        "def sequential_nn(input_dims):\n",
        "    cnn_model = Sequential()\n",
        "    cnn_model.add(Conv1D(32, 2, activation=\"relu\", input_shape=input_dims))\n",
        "    cnn_model.add(Dense(64, activation=\"relu\"))\n",
        "    cnn_model.add(Dropout(0.3))\n",
        "    cnn_model.add(BatchNormalization())\n",
        "    cnn_model.add(MaxPool1D())\n",
        "    cnn_model.add(Flatten())\n",
        "    cnn_model.add(Dense(32, activation=\"relu\"))\n",
        "    cnn_model.add(Dense(15, activation=\"relu\"))\n",
        "    cnn_model.add(Dense(1))\n",
        "\n",
        "    return cnn_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etaoQdi1uLdR"
      },
      "source": [
        "def rmse_loss(ytest, ypred):\n",
        "    return np.sqrt(mean_squared_error(ytest, ypred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-owxiIgUhWj",
        "outputId": "4dad0cbf-a2bf-4a07-9d00-4186f1b0e035"
      },
      "source": [
        "best_model_cols = \"\"\n",
        "best_score = 99999\n",
        "best_model = None\n",
        "\n",
        "NUM_EPOCHS = 50000\n",
        "BATCH_SIZE = 256\n",
        "TRAIN_TEST_SIZE = 0.15\n",
        "\n",
        "for combo in all_combinations:\n",
        "    combo = list(combo)\n",
        "    if len(combo) >= 2: \n",
        "        for loss_var in range(1,3):\n",
        "            loss_type = 'mae'\n",
        "            if loss_var % 2 ==0:\n",
        "                loss_type = 'mse'\n",
        "            combo = required_cols + combo\n",
        "            \n",
        "            train_vals = train_df[combo]\n",
        "            train_results = train_df['count']\n",
        "\n",
        "            train_vals_cnn = train_vals.to_numpy()\n",
        "            train_results_cnn = train_results.to_numpy()\n",
        "\n",
        "            train_vals_cnn = train_vals_cnn.reshape(train_vals_cnn.shape[0], \n",
        "                                                    train_vals_cnn.shape[1], 1)\n",
        "\n",
        "            xtrain, xtest, ytrain, ytest=train_test_split(train_vals_cnn, train_results_cnn, \n",
        "                                                            test_size=TRAIN_TEST_SIZE, random_state=42)\n",
        "            \n",
        "            cnn_model = sequential_nn(input_dims=(len(combo), 1))\n",
        "\n",
        "            cnn_model.compile(loss=loss_type, optimizer=\"adam\", metrics=['mae', 'mse'])\n",
        "\n",
        "            # print(\"Started Training\", list(combo))\n",
        "            # try on whole model?\n",
        "            # cnn_model.fit(train_vals_cnn, train_results_cnn, batch_size=64, epochs=1000, verbose=0)\n",
        "\n",
        "            cnn_model.fit(xtrain, ytrain, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, verbose=0)\n",
        "\n",
        "            # predict on the testing subset of the original training data\n",
        "            ypred = cnn_model.predict(xtest)\n",
        "\n",
        "            # score the model on the new test set\n",
        "            rms = np.sqrt(mean_squared_error(ytest, ypred))\n",
        "            if rms < best_score:\n",
        "                best_score = rms\n",
        "                best_model_cols = combo\n",
        "                best_model = cnn_model\n",
        "            print(rms, list(combo), \"with loss type\", loss_type)\n",
        "\n",
        "print(\"Best cols: \", best_model_cols)\n",
        "print(\"With RMSE: \", best_score)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82.35057898555314 ['hour', 'season', 'holiday', 'workingday', 'weather', 'temp', 'humidity'] with loss type mae\n",
            "83.64125802333912 ['hour', 'hour', 'season', 'holiday', 'workingday', 'weather', 'temp', 'humidity'] with loss type mse\n",
            "81.90216047214496 ['hour', 'season', 'holiday', 'workingday', 'weather', 'temp', 'humidity', 'windspeed'] with loss type mae\n",
            "72.13525380807054 ['hour', 'hour', 'season', 'holiday', 'workingday', 'weather', 'temp', 'humidity', 'windspeed'] with loss type mse\n",
            "Best cols:  ['hour', 'hour', 'season', 'holiday', 'workingday', 'weather', 'temp', 'humidity', 'windspeed']\n",
            "With RMSE:  72.13525380807054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8oLJ_IEDywy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a482bcba-e5b7-41d4-d57d-85c46f5ee645"
      },
      "source": [
        "print(\"Best cols: \", best_model_cols)\n",
        "print(\"With RMSE: \", best_score)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best cols:  ['hour', 'hour', 'season', 'holiday', 'workingday', 'weather', 'temp', 'humidity', 'windspeed']\n",
            "With RMSE:  72.13525380807054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZsec1kCeBXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1436fbf-8613-47d3-863e-0f740c452f39"
      },
      "source": [
        "best_model.save(\"best_model\")\n",
        "#print(ytest)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dWCrmK1Dd9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3420f5b7-a610-4ba8-df0a-c5b984563bd0"
      },
      "source": [
        "!zip best_model best_model/"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: best_model/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UrYvIy8HdMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62939aa-67e7-4390-9625-f57b0a26607c"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "\n",
        "def rmse(y_actual, y_predicted, **kwargs):\n",
        "    return np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
        "\n",
        "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
        "for model in model_list:\n",
        "    folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
        "    scores = cross_val_score(model, new_train_df[cols], new_train_df['count'], scoring=rmse_scorer, cv=folds)\n",
        "    print(scores)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-199.18508106 -197.48528981 -194.72540067 -195.94159701 -197.24219334]\n",
            "[-154.98707785 -155.99872065 -150.64972953 -159.08460825 -152.5441461 ]\n",
            "[-160.84234653 -161.09023941 -156.90967156 -163.95868214 -160.02447732]\n",
            "[-158.65941902 -160.90133469 -154.47777158 -163.72152314 -157.40522715]\n",
            "[-200.73793049 -212.4159268  -193.63891877 -201.44112526 -202.96828467]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmf2FnSoCz1W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "675473cc-ba8f-4ea0-ac45-fc31e79cb86e"
      },
      "source": [
        "# fit the model to the training subset of original training data\n",
        "best_model = None\n",
        "best_rmse = None\n",
        "for model in model_list:\n",
        "    #model.fit(new_train_df[cols], new_train_df['count'])\n",
        "\n",
        "    # predict on the testing subset of the original training data\n",
        "    pred_count = model.predict(new_test_df[cols])\n",
        "\n",
        "    # score the model on the new test set\n",
        "    rms = np.sqrt(mean_squared_error(new_test_df['count'],pred_count))\n",
        "    print(\"RMS error:\",rms)\n",
        "    if best_model is None or rms < best_rmse:\n",
        "        best_model = model\n",
        "        best_rmse = rms"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-17c70676f8b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# predict on the testing subset of the original training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpred_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_test_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# score the model on the new test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \"\"\"\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwfU9qIiQaMC"
      },
      "source": [
        "print(\"Best rmse: \", best_rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyz7i_eJC2Iv"
      },
      "source": [
        "# Creating the test file output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NhVh6ysC4Sp"
      },
      "source": [
        "# read in the test data\n",
        "test_df = pd.read_csv('test_luc.csv', header=0)\n",
        "print(\"\\nNumber of samples:\",test_df.shape[0] ,\"and number of features:\",test_df.shape[1],\"\\n\")\n",
        "\n",
        "# must add that new feature into the test data too, to use it in prediction\n",
        "test_df['hour'] = test_df['datetime'].map(hour_of_day)\n",
        "\n",
        "# show the test data output to be sure it read in correctly and added the column\n",
        "test_df.head()\n",
        "\n",
        "# fit the selected model TO YOUR FULL TRAINING SET\n",
        "#history = best_model.fit( train_df[cols], train_df['count'])\n",
        "\n",
        "# apply to the test data FOR WHICH YOU DON'T HAVE THE ANSWERS\n",
        "# (not the \"test set\" you used for model selection and tuning)\n",
        "final_cols = ['hour', 'season', 'holiday', 'workingday', 'weather', 'temp', 'humidity']\n",
        "test_cnn = test_df[final_cols].to_numpy()\n",
        "test_cnn = test_cnn.reshape(test_cnn.shape[0], test_cnn.shape[1], 1)\n",
        "pred_count = best_model.predict(test_cnn)\n",
        "\n",
        "# add the prediction column (in case you want to inspect it later)\n",
        "test_df['count'] = pred_count\n",
        "\n",
        "# save the predicted count as a csv with a header column and datetime row\n",
        "test_df = test_df[['datetime','count']].to_csv('my_prediction.csv', \n",
        "    index=False, header=True)\n",
        "print(\"Prediction complete. Saved as my_prediction.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsfJwD3zOgt2"
      },
      "source": [
        "# Scratch\n",
        "\n",
        "\n",
        "# Current RMS error of: 73.44168707407283 \n",
        "# Last RMS error: 79\n",
        "# print(\"RMS error of:\", rms, \"\\n\")\n",
        "# Best cols:  ['season', 'holiday', 'workingday', 'temp', 'windspeed']\n",
        "# With RMSE:  67.09231422002402\n",
        "\n",
        "\n",
        "# cnn_model = Sequential()\n",
        "# cnn_model.add(Dense(6,activation = tf.keras.activations.relu, input_shape=(6,1), \n",
        "#                        kernel_regularizer=regularizers.l2(0.01), \n",
        "#                        activity_regularizer=regularizers.l1(0.01)))\n",
        "# cnn_model.add(Dense(3, activation=\"relu\"))\n",
        "# cnn_model.add(Dropout(0.1, noise_shape=None))\n",
        "# cnn_model.add(Dense(1))\n",
        "# cnn_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['mae', 'mse'])\n",
        "\n",
        "# def rms_loss(y_actual, y_predicted):\n",
        "#     with tf.name_scope('rms_loss'):\n",
        "#         return np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
        "\n",
        "\n",
        "# cnn_model = Sequential()\n",
        "# cnn_model.add(Conv1D(32, 2, input_shape=(6, 1)))\n",
        "# cnn_model.add(Dense(64, activation=\"relu\"))\n",
        "# cnn_model.add(BatchNormalization())\n",
        "# cnn_model.add(MaxPool1D())\n",
        "# cnn_model.add(Flatten())\n",
        "# cnn_model.add(Dense(32, activation=\"relu\"))\n",
        "# cnn_model.add(Dropout(0.1))\n",
        "# cnn_model.add(Dense(1))\n",
        "\n",
        "\n",
        "    # model = Sequential()\n",
        "    # model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(6, 1)))\n",
        "    # model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    # model.add(Dropout(0.5))\n",
        "    # model.add(MaxPool1D(pool_size=2))\n",
        "    # model.add(Flatten())\n",
        "    # model.add(Dense(100, activation='relu'))\n",
        "    # model.add(Dense(1, activation='softmax'))\n",
        "  # Input dimensions: (None, 3, 3, 512)\n",
        "#   model.add(Flatten())\n",
        "#   model.add(Dense(512,activation='relu'))\n",
        "#   model.add(Dropout(0.1))\n",
        "#   model.add(Dense(1))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}